[{"name": "app.py", "content": "#\n# Heatmapper\n# Pairwise\n#\n# This file contains the ShinyLive application for Pairwise Heatmapper.\n# It can be run with the following command within this directory:\n#\t\tshinylive export . [site]\n# Where [site] is the destination of the site folder.\n#\n# If you would rather deploy the application as a PyShiny application,\n# run the following command within this directory:\n#\t\tshiny run\n#\n#\n\n\nfrom shiny import App, reactive, render, ui\nfrom matplotlib.pyplot import subplots, colorbar\nfrom scipy.spatial.distance import pdist, squareform\nfrom Bio.PDB import PDBParser\nfrom Bio import SeqIO\nfrom pandas import DataFrame\nfrom pathlib import Path\n\nfrom shared import Cache, NavBar, MainTab, Filter, ColumnType, FileSelection, TableValueUpdate\n\n\ndef server(input, output, session):\n\n\t# Information about the Examples\n\tInfo = {\n\t\t\"example1.txt\": \"This example dataset represents pairwise distances between C-alpha atoms in ubiquitin (1ubq).\",\n\t\t\"example2.txt\": \"This example dataset was generated randomly.\",\n\t\t\"example3.txt\": \"This example dataset was generated randomly.\",\n\t\t\"example4.fasta\": \"An example FASTA file.\",\n\t\t\"ala_phe_ala.pdb\": \"An example PDB file.\",\n\t}\n\n\tdef HandleData(n, i):\n\t\tsuffix = Path(n).suffix\n\t\tif suffix == \".pdb\": return PDBMatrix(n)\n\t\telif suffix == \".fasta\": return FASTAMatrix(n)\n\t\telse: return DataCache.DefaultHandler(n, i)\n\tDataCache = Cache(\"pairwise\", HandleData)\n\n\n\tdef FASTAMatrix(file):\n\t\t\"\"\"\n\t\t@brief Computes the pairwise matrix from a FASTA file.\n\t\t@param file: The path to the FASTA File\n\t\t@returns a pairwise matrix.\n\t\t\"\"\"\n\n\t\t# Get information from the file\n\t\trecords = list(SeqIO.parse(open(file), \"fasta\"))\n\t\tsequences = [str(record.seq) for record in records]\n\t\tcolumn_names = [record.id for record in records]\n\n\t\t# Get our K-Mer value\n\t\tk = input.K()\n\n\t\t# Generate the value\n\t\tdictionary = {}\n\t\tfor x, seq in enumerate(sequences):\n\t\t\tkmers = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n\t\t\tincrement = 1 / len(kmers)\n\t\t\tfor kmer in kmers:\n\t\t\t\t\tif kmer not in dictionary:\n\t\t\t\t\t\t\tdictionary[kmer] = [0.0] * len(sequences)\n\t\t\t\t\tdictionary[kmer][x] += increment\n\t\tfrequencies = DataFrame.from_dict(dictionary, orient='index')\n\n\t\t# Calculate matrix\n\t\tif input.MatrixType() == \"Distance\":\n\t\t\tdistances = pdist(frequencies.T, metric=input.DistanceMethod().lower())\n\t\t\treturn DataFrame(squareform(distances), index=column_names, columns=column_names)\n\t\telse:\n\t\t\treturn frequencies.corr(method=input.CorrelationMethod().lower())\n\n\n\tdef PDBMatrix(file):\n\t\t\"\"\"\n\t\t@brief Generates a pairwise matrix from a PDB file\n\t\t@param file: The path to a PDB file (Or BytesIO file if applicable)\n\t\t@returns The pairwise matrix.\n\t\t\"\"\"\n\n\t\tparser = PDBParser()\n\t\tstructure = parser.get_structure(\"protein\", file)\n\n\t\t# Extract atomic coordinates\n\t\tcoordinates = []\n\t\tfor model in structure:\n\t\t\tfor chain in model:\n\t\t\t\t\tif chain.id == input.Chain():\n\t\t\t\t\t\t\tfor residue in chain:\n\t\t\t\t\t\t\t\t\tfor atom in residue:\n\t\t\t\t\t\t\t\t\t\t\tcoordinates.append(atom.coord)\n\n\t\t# Calculate matrix\n\t\tif input.MatrixType() == \"Distance\":\n\t\t\tdistances = pdist(coordinates, metric=input.DistanceMethod().lower())\n\t\t\treturn DataFrame(squareform(distances))\n\t\telse:\n\t\t\treturn DataFrame(coordinates).corr(method=input.CorrelationMethod().lower())\n\n\n\tdef ChartMatrix(df):\n\t\t\"\"\"\n\t\t@brief Generates a pairwise matrix from charts\n\t\t@param df:\tThe DataFrame containing the data. This can either be a chart\n\t\t\t\t\t\t\t\tcontaining {x,y,z} columns outlining each point on a row, with\n\t\t\t\t\t\t\t\tan optional name column (Any fourth column), a chart to which\n\t\t\t\t\t\t\t\tan explicit \"Name\" column is provided, to which the first row\n\t\t\t\t\t\t\t\tand column are assumed variable names for an existing matrix,\n\t\t\t\t\t\t\t\tor the default, where it is assumed that the chart is an\n\t\t\t\t\t\t\t\tunlabeled collection either of points, or an existing matrix.\n\t\t@returns A DataFrame containing the provided data as a pairwise matrix\n\t\t\"\"\"\n\n\t\t# If \"Name\" is found, its assumed to be the label for the points.\n\t\tname_col = Filter(df.columns, ColumnType.Name, only_one=True, reject_unknown=True)\n\t\tif name_col: point_names = df[name_col]\n\n\t\t# If explicit coordinates ar eprovided, use them, with the final column used as labels.\n\t\tx_col = Filter(df.columns, ColumnType.X, only_one=True, reject_unknown=True)\n\t\ty_col = Filter(df.columns, ColumnType.Y, only_one=True, reject_unknown=True)\n\t\tz_col = Filter(df.columns, ColumnType.Z, only_one=True, reject_unknown=True)\n\n\t\tif x_col and y_col and z_col:\n\t\t\tcoordinates = df[[x_col, y_col, z_col]].values\n\t\t\tpoint_names = df[list(set(df.columns) - set([x_col, y_col, z_col]))[0]].values\n\n\t\telse:\n\n\t\t\t# If the first value is an integer, this is a distance matrix.\n\t\t\ttry:\n\t\t\t\tfloat(df.iloc[0,0])\n\t\t\t\tcoordinates = df.values\n\n\t\t\t# Otherwise, we assume the first row/column define the axis names.\n\t\t\texcept ValueError:\n\t\t\t\tcoordinates = df.iloc[:, 1:].values\n\n\t\t\tpoint_names = None\n\n\t\t# Calculate a distant matrix, and return it\n\t\tif input.MatrixType() == \"Distance\":\n\t\t\tdistances = pdist(coordinates, metric=input.DistanceMethod().lower())\n\t\t\treturn DataFrame(squareform(distances), index=point_names, columns=point_names)\n\t\telse:\n\t\t\treturn DataFrame(coordinates, index=point_names, columns=point_names).corr(method=input.CorrelationMethod().lower())\n\n\n\tasync def GenerateHeatmap():\n\t\t\"\"\"\n\t\t@brief Generates the Heatmap\n\t\t@returns The heatmap\n\t\t\"\"\"\n\n\t\twith ui.Progress(min=0, max=3) as p:\n\n\t\t\tp.set(value=1, message=\"Reading input...\")\n\t\t\tn, data = await DataCache.Load(input, return_n=True)\n\t\t\tif data.empty: return\n\t\t\tif Path(n).suffix not in [\".pdb\", \".fasta\"]: df = ChartMatrix(data)\n\t\t\telse: df = data\n\n\t\t\tp.set(value=2, message=\"Plotting...\")\n\t\t\tfig, ax = subplots()\n\t\t\tim = ax.imshow(df, cmap=input.ColorMap().lower(), interpolation=input.Interpolation().lower())\n\n\t\t\t# Visibility of features\n\t\t\tif \"legend\" in input.Features(): colorbar(im, ax=ax, label=\"Distance\")\n\n\t\t\tif \"y\" in input.Features():\n\t\t\t\tax.tick_params(axis=\"y\", labelsize=input.TextSize())\n\t\t\t\tax.set_yticks(range(len(df.columns)))\n\t\t\t\tax.set_yticklabels(df.columns)\n\t\t\telse:\n\t\t\t\tax.set_yticklabels([])\n\n\t\t\tif \"x\" in input.Features():\n\t\t\t\tax.tick_params(axis=\"x\", labelsize=input.TextSize())\n\t\t\t\tax.set_xticks(range(len(df.columns)))\n\t\t\t\tax.set_xticklabels(df.columns, rotation=90)\n\t\t\telse:\n\t\t\t\tax.set_xticklabels([])\n\n\t\t\t# Annotate each cell with its value\n\t\t\tif \"label\" in input.Features():\n\t\t\t\tfor i in range(df.shape[0]):\n\t\t\t\t\t\tfor j in range(df.shape[1]):\n\t\t\t\t\t\t\t\tax.text(j, i, '{:.2f}'.format(df.iloc[i, j]), ha='center', va='center', color='white')\n\n\t\t\tp.set(value=3, message=\"Done!\")\n\t\t\treturn ax\n\n\n\t@output\n\t@render.data_frame\n\t@reactive.event(input.SourceFile, input.File, input.Example, input.Update, input.Reset)\n\tasync def LoadedTable(): return await DataCache.Load(input)\n\n\n\t@output\n\t@render.plot\n\t@reactive.event(input.SourceFile, input.File, input.Example, input.Update, input.Reset, input.MatrixType, input.TextSize, input.DistanceMethod, input.CorrelationMethod, input.Interpolation, input.ColorMap, input.Features, input.Chain, input.K)\n\tasync def Heatmap(): return await GenerateHeatmap()\n\n\t@output\n\t@render.text\n\t@reactive.event(input.SourceFile, input.Example)\n\tdef ExampleInfo(): return Info[input.Example()]\n\n\n\t@render.download(filename=\"table.csv\")\n\tasync def DownloadTable(): yield (await DataCache.Load(input)).to_string()\n\n\n\t@reactive.Effect\n\t@reactive.event(input.Update)\n\tasync def Update(): await DataCache.Update(input)\n\n\n\t@reactive.Effect\n\t@reactive.event(input.Reset)\n\tasync def Reset(): await DataCache.Purge(input)\n\n\n\t@reactive.Effect\n\t@reactive.event(input.SourceFile, input.File, input.Example, input.TableRow, input.TableCol, input.Update, input.Reset)\n\tasync def UpdateTableValue(): TableValueUpdate(await DataCache.Load(input), input)\n\n\napp_ui = ui.page_fluid(\n\n\tNavBar(\"Pairwise\"),\n\n\tui.layout_sidebar(\n\t\tui.sidebar(\n\n\t\t\tFileSelection(\n\t\t\t\texamples={\n\t\t\t\t\"example1.txt\": \"Example 1\", \n\t\t\t\t\"example2.txt\": \"Example 2\", \n\t\t\t\t\"example3.txt\": \"Example 3\",\n\t\t\t\t\"example4.fasta\": \"Example 4\",\n\t\t\t\t\"ala_phe_ala.pdb\": \"Example 5\",\n\t\t\t\t},\n\t\t\t\ttypes=[\".csv\", \".txt\", \".xlsx\", \".pdb\", \".dat\", \".fasta\"]\n\t\t\t),\n\n\t\t\t# Specify Matrix Type\n\t\t\tui.input_radio_buttons(id=\"MatrixType\", label=\"Matrix Type\", choices=[\"Distance\", \"Correlation\"], selected=\"Distance\", inline=True),\n\n\t\t\t# Customize the text size of the axes.\n\t\t\tui.input_numeric(id=\"TextSize\", label=\"Text Size\", value=8, min=1, max=50, step=1),\n\n\t\t\t# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html\n\t\t\tui.panel_conditional(\n\t\t\t\t\"input.MatrixType === 'Distance'\",\n\t\t\t\tui.input_select(id=\"DistanceMethod\", label=\"Distance Method\", choices=[\n\t\t\t\t\t\"Braycurtis\", \"Canberra\", \"Chebyshev\", \"Cityblock\", \"Correlation\", \"Cosine\", \"Dice\", \"Euclidean\", \"Hamming\", \"Jaccard\", \"Jensenshannon\", \"Kulczynski1\", \"Mahalanobis\", \"Matching\", \"Minkowski\", \"Rogerstanimoto\", \"Russellrao\", \"Seuclidean\", \"Sokalmichener\", \"Sokalsneath\", \"Sqeuclidean\", \"Yule\"], selected=\"Euclidean\"),\n\t\t\t),\n\n\t\t\t# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\n\t\t\tui.panel_conditional(\n\t\t\t\t\"input.MatrixType === 'Correlation'\",\n\t\t\t\tui.input_select(id=\"CorrelationMethod\", label=\"Correlation Method\", choices=[\"Pearson\", \"Kendall\", \"Spearman\"], selected=\"Pearson\"),\n\t\t\t),\n\n\t\t\t# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\n\t\t\tui.input_select(id=\"Interpolation\", label=\"Interpolation\", choices=[\"None\", \"Antialiased\", \"Nearest\", \"Bilinear\", \"Bicubic\", \"Spline16\", \"Spline36\", \"Hanning\", \"Hamming\", \"Hermite\", \"Kaiser\", \"Quadric\", \"Catrom\", \"Gaussian\", \"Bessel\", \"Mitchell\", \"Sinc\", \"Lanczos\", \"Blackman\"], selected=\"Nearest\"),\n\n\t\t\t# Set the ColorMap used.\n\t\t\tui.input_select(id=\"ColorMap\", label=\"Color Map\", choices=[\"Viridis\", \"Plasma\", \"Inferno\", \"Magma\", \"Cividis\"], selected=\"Viridis\"),\n\n\t\t\t# Customize what aspects of the heatmap are visible\n\t\t\tui.input_checkbox_group(id=\"Features\", label=\"Heatmap Features\",\n\t\t\t\t\tchoices={\"x\": \"X Labels\", \"y\": \"Y Labels\", \"label\": \"Data Labels\", \"legend\": \"Legend\"},\n\t\t\t\t\tselected=[\"legend\"]),\n\n\t\t\t# Specify the PDB Chain\n\t\t\tui.input_text(\"Chain\", \"PDB Chain\", \"A\"),\n\n\t\t\t# Customize the K-mer to compute for FASTA sequences\n\t\t\tui.input_numeric(id=\"K\", label=\"K-Mer Length\", value=3, min=3, max=5, step=1),\n\n\t\t\t# Add the download buttons.\n\t\t\tui.download_button(\"DownloadTable\", \"Download Table\"),\n\t\t),\n\n\t\t# Add the main interface tabs.\n\t\tMainTab(),\n\t)\n)\n\napp = App(app_ui, server)\n", "type": "text"}, {"name": "requirements.txt", "content": "biopython", "type": "text"}, {"name": "shared.py", "content": "#\n# Heatmapper\n# Shared\n#\n# This file contains shared functionality between Heatmapper applications. It is not a standalone application.\n# Due to the way ShinyLive exports applications, this file is symlinked into each project to reduce redundancy.\n#\n\nfrom shiny import ui\nfrom shiny.types import FileInfo\nfrom pandas import DataFrame, read_csv, read_excel, read_table\nfrom io import BytesIO\nfrom sys import modules\nfrom pathlib import Path\nfrom enum import Enum\nfrom os.path import exists\n\n# Used for fetching web resources in a variety of fashions.\nURL = \"https://wishartlab.github.io/heatmapper2\"\nRaw = \"https://raw.githubusercontent.com/WishartLab/heatmapper2/main\"\n\n# Define the Server and Port of the Shiny instances (Port is incremented)\n# Change these if Heatmapper is running on a server.\nServer = \"http://35.208.86.138\"\nPort = 8000\n\n\n# Detect the running environment\nif \"pyodide\" in modules:\n\tfrom pyodide.http import pyfetch\n\tPyodide = True\nelse:\n\tPyodide = False\n\n\nclass ColumnType(Enum): Time = 0; Name = 1; Value = 2; Longitude = 3; Latitude = 4; X = 5; Y = 6; Z = 7; Cluster = 8; Free = 9; Spatial = 10;\nColumns = {\n\tColumnType.Time: {\"time\", \"date\", \"year\"},\n\tColumnType.Name: {\"name\", \"orf\", \"uniqid\", \"face\", \"triangle\"},\n\tColumnType.Value: {\"value\", \"weight\", \"intensity\", \"in_tissue\"},\n\tColumnType.Longitude: {\"longitude\", \"long\"},\n\tColumnType.Latitude: {\"latitude\", \"lat\"},\n\tColumnType.X: {\"x\"},\n\tColumnType.Y: {\"y\"},\n\tColumnType.Z: {\"z\"},\n\tColumnType.Cluster: {\"cell type\", \"celltype_mapped_refined\", \"cluster\", \"cell_class\", \"cell_subclass\", \"cell_cluster\"},\n\tColumnType.Free: {None},\n\tColumnType.Spatial: {\"spatial\"}\n}\n\n\ndef Filter(columns, ctype: ColumnType, good: list = [], bad: list = [], only_one=False, ui_element=None, reject_unknown=False):\n\t\"\"\"\n\t@brief Filters available column names based on what input we want\n\t@param columns: The columns of the DataFrame (Usually just df.columns)\n\t@param ctype: The type of column we're looking for (Look at the ColumnType Enum)\n\t@param good: A list of column names on top of those defined by the type to be included\n\t@param bad: A list of column names on top of those defined by the type to be excluded from the result.\n\t@param only_one: Only return a single result, so the variable can be used immediately.\n\t@param ui_element: An optional Shiny selection input to update.\n\t@param reject_unknown: Only include columns explicitly defined\n\t@return: A list of column names to use.\n\t\"\"\"\n\n\t# Fold cases\n\tfolded = [column.lower() for column in columns]\n\n\t# Add and remove what user asked for, filtering None\n\toptions = set(folded)\n\tif bad: options -= set([b.lower() for b in bad if b])\n\tif good: options &= set([g.lower() for g in good if g])\n\n\t# Take an intersection of our columns and the type we want. If there is a match, return those\n\t# Otherwise, remove all columns we know it shouldn't be, and return that instead.\n\tintersection = options & Columns[ctype]\n\tif intersection or reject_unknown: options = intersection\n\telse:\n\t\tfor key, value in Columns.items():\n\t\t\tif key != ctype: options -= value\n\n\t# Get the valid indices, and sort them in ascending order\n\tindices = [folded.index(value) for value in options]\n\tindices.sort()\n\n\t# Get the original column names, without case-folding, and return as a list.\n\treassembled = [columns[index] for index in indices]\n\tif not reassembled: return None\n\n\t# Update a UI element, if one was provided\n\tif ui_element is not None: ui.update_select(id=ui_element, choices=reassembled, selected=reassembled[0])\n\treturn reassembled[0] if only_one else reassembled\n\n\nclass Cache:\n\t\"\"\"\n\t@brief A class that encompasses fetching/storing web resources.\n\t\"\"\"\n\n\t@staticmethod\n\tdef HandleDataFrame(i, function):\n\t\t\"\"\"\n\t\t@brief Handle DataFrame's\n\t\t@param i: The binary of the file\n\t\t@param function: The pandas function to use to read the file.\n\t\t@returns A DataFrame\n\t\t\"\"\"\n\n\t\t# Read the table once.\n\t\tdf = function(i).fillna(0)\n\n\t\t# If the first column value is a float, we assume it's data, and not column names.\n\t\t# Re-read the DataFrame with generic column names instead\n\t\ttry:\n\t\t\tfloat(df.columns[0])\n\t\t\ti.seek(0)\n\t\t\tdf = function(i, header=None, names=[f\"Column {i}\" for i in range(df.shape[1])])\n\t\texcept ValueError: pass\n\t\treturn df\n\n\n\t@staticmethod\n\tdef DefaultHandler(n, i):\n\t\t\"\"\"\n\t\t@brief The default handler. It can handle csv, xlsx, and defaults all other files to read_table\n\t\t@param n: The name of the file. We use this for pattern matching against the suffix.\n\t\t@param i: The binary of the file (Either via read() or BytesIO())\n\t\t@returns: An object, if the provided file is supported, None otherwise.\n\t\t\"\"\"\n\n\t\tsuffix = Path(n).suffix\n\t\tif suffix == \".csv\": return Cache.HandleDataFrame(i, read_csv)\n\t\telif suffix == \".xlsx\": return Cache.HandleDataFrame(i, read_excel)\n\t\telse: return Cache.HandleDataFrame(i, read_table)\n\n\n\tasync def _remote(self, url):\n\t\tif url not in self._primary:\n\t\t\tr = await pyfetch(url);\n\t\t\tif not r.ok: return None\n\t\t\telse: self._primary[url] = await r.bytes()\n\t\treturn self._primary[url]\n\n\n\tasync def _local(self, url):\n\t\tif not exists(url): return None\n\t\telif url not in self._primary:\n\t\t\tself._primary[url] = open(url, \"rb\").read()\n\t\treturn self._primary[url]\n\n\n\tdef _local_sync(self, url):\n\t\tif not exists(url): return None\n\t\telif url not in self._primary:\n\t\t\tself._primary[url] = open(url, \"rb\").read()\n\t\treturn self._primary[url]\n\n\n\tdef __init__(self, project, DataHandler = DefaultHandler):\n\t\t\"\"\"\n\t\t@brief Initialize an instance of the Cache object.\n\t\t@param project: The name of the project. This is used to fetch web resources.\n\t\t@param DataHandler:\tThe function that should be called to process files. It should\n\t\t\t\t\t\t\t\t\t\t\t\ttake a name, and a binary stream, and return a DataFrame.\n\t\t\"\"\"\n\n\t\t# The primary cache now serves as a file agnostic cache, containing the raw bytes of files.\n\t\tself._primary = {}\n\n\t\t# The Secondary cache now serves as the transformed output through the handler. There is now\n\t\t# no need to specify mutability because the primary cache doesn't contain data that can be changed.\n\t\t# It serves solely as a cache for the Handler if the user throws out whatever is in the secondary.\n\t\tself._secondary = {}\n\n\t\t# The data handler for processing the binary files.\n\t\tself._handler = DataHandler\n\n\t\t# If we're in a Pyodide environment, we fetch resources from the web.\n\t\tif Pyodide:\n\t\t\tself._download = lambda url: self._remote(url)\n\t\t\tself._source = f\"{Raw}/{project}/example_input/\"\n\n\t\t# Otherwise, we fetch locally.\n\t\telse:\n\t\t\tself._download = lambda url: self._local(url)\n\t\t\tself._source = \"../example_input/\"\n\n\n\tdef SyncLoad(self, input, source_file=None, example_file=None, source=None, input_switch=None, default=DataFrame(), return_n=False):\n\t\t\"\"\"\n\t\t@brief A synchronous loading function that only supports local files\n\t\t@info See Load() for more information\n\t\t\"\"\"\n\t\tif source_file is None: source_file = input.File()\n\t\tif example_file is None: example_file = input.Example()\n\t\tif source is None: source = self._source\n\t\tif input_switch is None: input_switch = input.SourceFile()\n\n\t\t# Grab an uploaded file, if its done, or grab an example (Using a cache to prevent redownload)\n\t\tif input_switch == \"Upload\":\n\t\t\tfile: list[FileInfo] | None = source_file\n\t\t\tif file is None: return (None, default) if return_n else default\n\n\t\t\t# The datapath can be immediately used to load examples, but we explicitly need to use\n\t\t\t# Local as a user uploaded file will always be fetched on disk.\n\t\t\tn = str(file[0][\"datapath\"])\n\t\t\traw = self._local_sync(n)\n\n\t\t# Example files, conversely, can be on disk or on a server depending on whether we're in a WASM environment.\n\t\telse:\n\t\t\tn = str(source + example_file)\n\t\t\traw = self._local_sync(n)\n\n\t\t# If the secondary cache hasn't been populated (Or was purge by the user), populate it.\n\t\tif n not in self._secondary:\n\t\t\tself._secondary[n] = self._handler(n, BytesIO(raw))\n\n\t\treturn (n, self._secondary[n]) if return_n else self._secondary[n]\n\n\n\tasync def Load(self, input, source_file=None, example_file=None, source=None, input_switch=None, default=DataFrame(), return_n=False):\n\t\t\"\"\"\n\t\t@brief Caches whatever the user has currently uploaded/selection, returning the identifier within the secondary cache.\n\t\t@param input: The Shiny input variable. Importantly, these must be defined:\n\t\t\tinput.File: The uploaded file\n\t\t\tinput.Example: The selected example file\n\t\t\tinput.SourceFile: Whether the user wants \"Upload\" or \"Example\"\n\t\t@param source_file: The input ID that should be used to fetch the file (Defaults to input.File() if None)\n\t\t@param example_file: The input ID that should be used to fetch th example (Defaults to input.Example() if None)\n\t\t@param input_switch:\tThe input ID to check for Upload/Example/Other. The value is compared against \"Upload\" for user\n\t\t\t\t\t\t\t\t\t\t\t\t\tuploaded items, and defaults to fetching example_file otherwise. (Defaults to input.SourceFile())\n\t\t@param default:\tThe object that should be returned if files cannot be fetched. Ensures that Load will always return an\n\t\t\t\t\t\t\t\t\t\tobject, avoiding the needing to check output. Defaults to a DataFrame. The object should be able to\n\t\t\t\t\t\t\t\t\t\tinitialize without arguments.\n\t\t@param return_n: Return the filename for post-processing.\n\t\t\"\"\"\n\n\t\tif source_file is None: source_file = input.File()\n\t\tif example_file is None: example_file = input.Example()\n\t\tif source is None: source = self._source\n\t\tif input_switch is None: input_switch = input.SourceFile()\n\n\t\t# Grab an uploaded file, if its done, or grab an example (Using a cache to prevent redownload)\n\t\tif input_switch == \"Upload\":\n\t\t\tfile: list[FileInfo] | None = source_file\n\t\t\tif file is None: return (None, default) if return_n else default\n\n\t\t\t# The datapath can be immediately used to load examples, but we explicitly need to use\n\t\t\t# Local as a user uploaded file will always be fetched on disk.\n\t\t\tn = str(file[0][\"datapath\"])\n\t\t\traw = await self._local(n)\n\n\t\t# Example files, conversely, can be on disk or on a server depending on whether we're in a WASM environment.\n\t\telse:\n\t\t\tn = str(source + example_file)\n\t\t\traw = await self._download(n)\n\n\t\t# If the secondary cache hasn't been populated (Or was purge by the user), populate it.\n\t\tif n not in self._secondary:\n\t\t\tself._secondary[n] = self._handler(n, BytesIO(raw))\n\n\t\treturn (n, self._secondary[n]) if return_n else self._secondary[n]\n\n\n\tasync def Update(self, input):\n\t\t\"\"\"\n\t\t@brief Updates information within the secondary cache based on user selection\n\t\t@param input: The Shiny input. Importantly, these must be defined:\n\t\t\tinput.TableRow: The row to modify\n\t\t\tinput.TableCol: The column to modify\n\t\t\tinput.TableVal: What the user wants to set as the new value\n\t\t@info This function should be called on a reactive hook for a \"Update\" button.\n\t\t\"\"\"\n\n\t\t# Get the data\n\t\tdf = await self.Load(input)\n\t\tif not type(df) is DataFrame: return\n\n\t\trow_count, column_count = df.shape\n\t\trow, column = input.TableRow(), input.TableCol()\n\n\t\t# So long as row and column are sane, update.\n\t\tif row < row_count and column < column_count:\n\t\t\ttry:\n\t\t\t\tif input.Type() == \"Integer\": df.iloc[row, column] = int(input.TableVal())\n\t\t\t\telif input.Type() == \"Float\": df.iloc[row, column] = float(input.TableVal())\n\t\t\t\telse: df.iloc[row, column] = input.TableVal()\n\t\t\texcept ValueError: pass\n\n\n\tasync def Purge(self, input, source_file=None, example_file=None, source=None):\n\t\t\"\"\"\n\t\t@brief Purges the secondary cache of whatever the user has uploaded/selected\n\t\t@param input: The Shiny input. See N() for required objects.\n\t\t@param source_file: The source ID, defaults to input.File()\n\t\t@param example_file: The example ID, defaults to input.Example()\n\t\t@info This function should be called on a reactive hook for a \"Reset\" button.\n\t\t\"\"\"\n\n\t\tif source_file is None: source_file = input.File()\n\t\tif example_file is None: example_file = input.Example()\n\t\tif source is None: source = self._source\n\n\t\tif input.SourceFile() == \"Upload\":\n\t\t\tfile: list[FileInfo] | None = source_file\n\t\t\tif file is None: return None\n\t\t\tn = file[0][\"datapath\"]\n\t\telse: n = source + example_file\n\t\tdel self._secondary[n]\n\n\ndef TableValueUpdate(df, input):\n\t\"\"\"\n\t@brief Updates the value displayed in the TableVal based on the current selection\n\t@param df The DataFrame\n\t@param input The shiny input\n\t\"\"\"\n\n\tif not df.empty:\n\t\trows, columns = df.shape\n\t\trow, column = int(input.TableRow()), int(input.TableCol())\n\t\tif 0 <= row <= rows and 0 <= column <= columns:\n\t\t\tui.update_text(id=\"TableVal\", label=\"Value (\" + str(df.iloc[row, column]) + \")\")\n\n\ndef NavBar(current):\n\t\"\"\"\n\t@brief Returns a Navigation Bar for each project, with the current project selected.\n\t@returns A list, containing a ui.panel_title, and a ui.navset_bar.\n\t\"\"\"\n\n\tSources = {\n\t\t\"expression\": URL if Pyodide else f\"{Server}:{Port}\",\n\t\t\"pairwise\": URL if Pyodide else f\"{Server}:{Port + 1}\",\n\t\t\"image\": URL if Pyodide else f\"{Server}:{Port + 2}\",\n\t\t\"geomap\": URL if Pyodide else f\"{Server}:{Port + 3}\",\n\t\t\"geocoordinate\": URL if Pyodide else f\"{Server}:{Port + 4}\",\n\t\t\"3d\": f\"{Server}:{Port + 5}\",\n\t\t\"spatial\": f\"{Server}:{Port + 6}\",\n\t}\n\n\treturn (\n\t\tui.panel_title(title=None, window_title=\"Heatmapper\"),\n\t\t\tui.navset_bar(\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"expression\"]}\">Expression</a>'), value=\"Expression\"),\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"pairwise\"]}\">Pairwise</a>'), value=\"Pairwise\"),\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"image\"]}\">Image</a>'), value=\"Image\"),\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"geomap\"]}\">Geomap</a>'), value=\"Geomap\"),\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"geocoordinate\"]}\">Geocoordinate</a>'), value=\"Geocoordinate\"),\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"3d\"]}\">3D</a>'), value=\"3D\"),\n\t\t\t\tui.nav_panel(ui.HTML(f'<a href=\"{Sources[\"spatial\"]}\">Spatial</a>'), value=\"Spatial\"),\n\t\t\t\tui.nav_panel(ui.HTML('<a href=https://github.com/WishartLab/heatmapper2/wiki target=\"_blank\" rel=\"noopener noreferrer\">About</a>'), value=\"About\"),\n\t\t\t\ttitle=\"Heatmapper\",\n\t\t\t\tselected=current,\n\t\t),\n\t)\n\n\ndef FileSelection(examples, types, upload_label=\"Choose a File\", multiple=False, default=\"Example\"):\n\t\"\"\"\n\t@brief Returns the file selection dialog for the user to upload/select an example\n\t@param examples: Either a list of example file names, or a dictionary mapping\n\t@param types: The valid file extensions for user uploaded files.\n\t@returns A list, containing the necessary ui components for uploading/selecting\n\t@info The returns elements are named:\n\t\tinput.SourceFile: The ui.input_radio_buttons for whether the user wants to choose an \"Example\" or \"Upload\"\n\t\tinput.File: The ui.input_file for user uploaded files.\n\t\tinput.Example: The ui.input_select for an example file selection\n\t\"\"\"\n\n\t# If the user needs help with the formatting.\n\treturn [ui.HTML('<a href=https://github.com/WishartLab/heatmapper2/wiki target=\"_blank\" rel=\"noopener noreferrer\">Data Format</a>'),\n\n\t# Specify whether to use example files, or upload one.\n\tui.input_radio_buttons(id=\"SourceFile\", label=\"Specify a Source File\", choices=[\"Example\", \"Upload\"], selected=default, inline=True),\n\n\t# Only display an input dialog if the user is one Upload\n\tui.panel_conditional(\n\t\t\"input.SourceFile === 'Upload'\",\n\t\tui.input_file(\"File\", upload_label, accept=types, multiple=multiple),\n\t),\n\n\t# Otherwise, add the example selection and an info button.\n\tui.panel_conditional(\n\t\t\"input.SourceFile === 'Example'\",\n\t\tui.layout_columns(\n\t\t\tui.input_select(id=\"Example\", label=None, choices=examples, multiple=False),\n\t\t\tui.popover(ui.input_action_link(id=\"ExampleInfoButton\", label=\"Info\"), ui.output_text(\"ExampleInfo\")),\n\t\t\tcol_widths=[8,2],\n\t\t)\n\t)]\n\n\ndef MainTab(*args, m_type=ui.output_plot):\n\treturn ui.navset_tab(\n\t\tui.nav_panel(\"Interactive\", m_type(\"Heatmap\", height=\"75vh\"), value=\"Interactive\"),\n\t\tui.nav_panel(\"Table\",\n\t\t\tui.layout_columns(\n\t\t\t\tui.input_numeric(\"TableRow\", \"Row\", 0, min=0),\n\t\t\t\tui.input_numeric(\"TableCol\", \"Column\", 0, min=0),\n\t\t\t\tui.input_text(\"TableVal\", \"Value\", 0),\n\t\t\t\tui.input_select(id=\"Type\", label=\"Datatype\", choices=[\"Integer\", \"Float\", \"String\"]),\n\t\t\t\tcol_widths=[2,2,6,2],\n\t\t\t),\n\t\t\tui.layout_columns(\n\t\t\t\tui.input_action_button(\"Update\", \"Update\"),\n\t\t\t\tui.input_action_button(\"Reset\", \"Reset Values\"),\n\t\t\t),\n\t\t\tui.output_data_frame(\"LoadedTable\")\n\t\t),\n\t\t*args,\n\t\tid=\"MainTab\"\n\t)\n", "type": "text"}]